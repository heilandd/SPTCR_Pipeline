#!/usr/bin/env python
import argparse
from random import sample
parser = argparse.ArgumentParser(description='Script to UMI Correct TCR Table generated by SPTCR-seq Pipeline')

parser.add_argument('-O','--OUT',help= "Path to Outfolder", required=False, default='./' )
parser.add_argument('-igb','--IGB',help="Path to IgBlast csv that should be UMI-corrected. IMPORTANT: Expects Columns: Locus, V, D, J, CDR3_aa, Spatial Barcode, UMI as generated by SPTCR-seq Pipeline",default="")
parser.add_argument('-bc','--BCOL',help="Name of the Barcode Column in the Input csv", required=False,default="Spatial Barcode" )
parser.add_argument('-umi','--UMICOL',help="Name of the UMI Column in the Input csv", required=False,default="UMI" )
parser.add_argument('-n','--NAME',help="Name of the Pipeline. Defaults to fastq basename_date", required=False,default="" )
parser.add_argument('-d','--STRDIST',help="String Distance to use for UMI Clustering", default=2 )


args = parser.parse_args()

arg_vars = vars(args)
##################### Import Modules ############################
from umi_tools import UMIClusterer
from collections import defaultdict, Counter
import pandas as pd
from tqdm import tqdm
import os

#######################################################
#################### Variables ########################
OUT=str(arg_vars["OUT"])
sample_name=arg_vars["NAME"]
read_dir=arg_vars["IGB"]
string_dist=arg_vars["STRDIST"]
barcode_col=arg_vars["BCOL"]
umi_col=arg_vars["UMICOL"]

#######################################################
############ Summarizing and Preparing DF #############

## Reading in IGB
igb=pd.read_csv(read_dir)

### Preparing Data
## Subsetting and Merging V,(D),J Columns to one
vdj=igb[igb['Locus'].isin(['TRB','TRD'])]
vdj=vdj.dropna(subset=['Locus','V','D','J','CDR3_aa'])
vdj[['Locus','V','D','J','CDR3_aa']]=vdj[['Locus','V','D','J','CDR3_aa']].astype(str)
vdj['TCR']=vdj[['Locus','V','D','J','CDR3_aa']].agg('_'.join,axis=1)
vdj=vdj[['TCR',barcode_col,umi_col]]

vj=igb[igb['Locus'].isin(['TRA','TRG'])]
vj=vj.dropna(subset=['Locus','V','J','CDR3_aa'])
vj[['Locus','V','J','CDR3_aa']]=vj[['Locus','V','J','CDR3_aa']].astype(str)
vj['TCR']=vj[['Locus','V','J','CDR3_aa']].agg('_'.join,axis=1)
vj=vj[['TCR',barcode_col,umi_col]]

## Grouping TCR Columns to one
vdj=vdj.groupby(['TCR','Spatial Barcode'])['UMI'].apply(list).reset_index(name='UMI List')
vdj['Uncorrected Count']=vdj.apply(lambda x: len(x['UMI List']),axis='columns')
vdj=vdj.sort_values(by='Uncorrected Count',ascending=False).reset_index(drop=True)


vj=vj.groupby(['TCR','Spatial Barcode'])['UMI'].apply(list).reset_index(name='UMI List')
print(vj)
vj['Uncorrected Count']=""
vj['Uncorrected Count']=vj.apply(lambda x: len(x['UMI List']),axis='columns')
vj=vj.sort_values(by='Uncorrected Count',ascending=False).reset_index(drop=True)

#######################################################
##################### UMI Correcting ##################
clusterer = UMIClusterer(cluster_method="directional")

tcrs=pd.concat([vdj,vj])
tcrs=tcrs.reset_index(drop=True)

tcrs['UMI Corrected']=""
for index, row in tqdm(tcrs.iterrows()):
    if row['Uncorrected Count'] > 1:
        umi_bytes=[str.encode(umi) for umi in row['UMI List']]
        umis=dict(Counter(umi_bytes))
        clustered_umis = clusterer(umis, threshold=2)
        tcrs.loc[index,'UMI Corrected']=len(clustered_umis)
    else:
        tcrs.loc[index,'UMI Corrected']=1


#######################################################
##################### Write File Out ##################

#out_path=os.path(OUT)
write_name=sample_name+"_igb_corr_umi_corrected.csv"
outpath=os.path.join(OUT,write_name)
tcrs.to_csv(outpath,index=False)